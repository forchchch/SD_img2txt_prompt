{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012dc878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open_clip\n",
    "# open_clip.list_pretrained()\n",
    "# model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
    "# tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# image = preprocess( Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/vase/01.jpg\" ) ).unsqueeze(0)\n",
    "# text = tokenizer([\"a vase on the table\", \"many colorful flowers\", \"a cat on the grass\"])\n",
    "# with torch.no_grad():\n",
    "#     image_feature = model.encode_image(image)\n",
    "#     text_feature = model.encode_text(text)\n",
    "#     image_feature /= image_feature.norm(dim=-1, keepdim=True)\n",
    "#     text_feature /= text_feature.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "#     text_prob = (100.0 * image_feature @ text_feature.T).softmax(dim=-1)\n",
    "#     print(text_prob)\n",
    "# open_clip.list_pretrained()\n",
    "# vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "# from torchvision import transforms \n",
    "# transform = transforms.Compose([\n",
    "#         transforms.Resize(256, interpolation=3),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "#     ])\n",
    "# image = Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/vase/01.jpg\" )\n",
    "# image1 = transform(image).unsqueeze(0)\n",
    "# vits16(image1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from evaluator import Evaluator\n",
    "# my_evaluator = Evaluator(device = \"cuda:0\", model_name = \"ViT-H-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891ab9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# img1 = Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/vase/01.jpg\" )\n",
    "# # img2 = Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/vase/02.jpg\" )\n",
    "# img2 = Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/lora/disen_dreambooth/output_dreambooth/t_disenft_0.1origin_vase/generated_images/133_800_edit.jpg\")\n",
    "# img3 = Image.open(\"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/backpack/01.jpg\" )\n",
    "# text = \"a vase on the beach\"\n",
    "# vase_sim = my_evaluator.image_similarity(img1, img2).cpu().numpy()\n",
    "# vase_bag_sim = my_evaluator.image_similarity(img2, img3).cpu().numpy()\n",
    "# print(vase_sim, vase_bag_sim)\n",
    "# vase_text_sim = my_evaluator.txt_img_similarity(text, img1).cpu().numpy()\n",
    "# g_vase_text_sim = my_evaluator.txt_img_similarity(text, img2).cpu().numpy()\n",
    "# bag_text_sim = my_evaluator.txt_img_similarity(text, img3).cpu().numpy()\n",
    "# print(vase_text_sim, g_vase_text_sim, bag_text_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c21e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_token = \"<s1>|<s2>\"\n",
    "# class_token = \"backpack\"\n",
    "# prompt_list = [\n",
    "# 'a {0} {1} in the jungle'.format(unique_token, class_token),\n",
    "# 'a {0} {1} in the snow'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on the beach'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on a cobblestone street'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of pink fabric'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of a wooden floor'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with a city in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with a mountain in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with a blue house in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of a purple rug in a forest'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with a wheat field in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with a tree and autumn leaves in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} with the Eiffel Tower in the background'.format(unique_token, class_token),\n",
    "# 'a {0} {1} floating on top of water'.format(unique_token, class_token),\n",
    "# 'a {0} {1} floating in an ocean of milk'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of green grass with sunflowers around it'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of a mirror'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of the sidewalk in a crowded street'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of a dirt road'.format(unique_token, class_token),\n",
    "# 'a {0} {1} on top of a white rug'.format(unique_token, class_token),\n",
    "# 'a red {0} {1}'.format(unique_token, class_token),\n",
    "# 'a purple {0} {1}'.format(unique_token, class_token),\n",
    "# 'a shiny {0} {1}'.format(unique_token, class_token),\n",
    "# 'a wet {0} {1}'.format(unique_token, class_token),\n",
    "# 'a cube shaped {0} {1}'.format(unique_token, class_token)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25317ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import reconstruction_metric, text_img_match_metric\n",
    "from evaluator import Evaluator\n",
    "evalor = Evaluator(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc4ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171116182298372\n"
     ]
    }
   ],
   "source": [
    "origin_root = \"/DATA/DATANAS1/chenhong/diffusion_research/dreambooth_data/backpack\"\n",
    "gen_root = \"/DATA/DATANAS1/chenhong/diffusion_research/lora/disen_dreambooth/output_dreambooth/our_versions/my_base_global0.05/generated_images/499_3000\"\n",
    "recon_sim = reconstruction_metric(origin_root, gen_root, evalor)\n",
    "print(recon_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6995c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3603767222828335\n"
     ]
    }
   ],
   "source": [
    "#计算text匹配程度的时候，储存图片的名字按照prompt对应的id+.jpg命名\n",
    "#比如第0个prompt，图片就存成“0.jpg”,unique token加不加特殊字符我测了一次，好像影响不大\n",
    "match_metric = text_img_match_metric(gen_root, evalor, unique_token=\"\", class_token=\"backpack\", mode=\"train\")\n",
    "print(match_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a553c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
